# ğŸ›ï¸ Greek History & Mythology RAG Chatbot

## ğŸŒŸ Project Overview

This project is a **Retrieval-Augmented Generation (RAG) chatbot** specialized in **Ancient Greek history and mythology**.  

It uses:

- âš¡ **FAISS** for similarity search over PDF chunks.  
- ğŸ§  **Embeddings** via `text-embedding-004` for both documents and queries.  
- ğŸ¤– **Google Gemini LLM** to generate accurate answers grounded in the retrieved context.  

The chatbot ensures that responses are **factual and context-aware**, based on your PDF datasets.

---

## âœ¨ Features

- ğŸº Ask questions about Greek history, mythology, gods, heroes, and events.  
- ğŸš€ FAISS-based fast similarity search over large text datasets.  
- ğŸ’¡ Gemini LLM provides reasoning-based, detailed answers.  
- ğŸ“š Easy to expand with new PDF documents.

---

## ğŸ› ï¸ Project Workflow

1. **ğŸ“‚ Data Preparation**  
   - Collect PDFs (Greek history and mythology) in the `data/` folder.

2. **ğŸ“„ Text Extraction & Chunking**  
   - Extract text using `PyPDF2`.  
   - Chunk text (~500 characters) to optimize embeddings.

3. **ğŸ”— Embedding & Indexing**  
   - Convert chunks to embeddings via Gemini `text-embedding-004`.  
   - Build FAISS index and save (`greek_index.faiss`).  
   - Pickle the text chunks (`chunks.pkl`).

4. **ğŸ¤– Query & Answer**  
   - Embed user query.  
   - Retrieve top-k chunks from FAISS.  
   - Generate answer via Gemini LLM using only retrieved context.

5. **ğŸ§ª Testing**  
   - CLI-based testing prints retrieved chunks, distances, and the generated answer.


---

## ğŸ“‚ Project Structure
```
greekmodel/
â”‚
â”œâ”€ data/                 # ğŸ“„ PDFs for Greek history/mythology
â”‚   â”œâ”€ greek_history.pdf
â”‚   â””â”€ greek_myths.pdf
â”‚
â”œâ”€ build_rag_index.py    # ğŸ› ï¸ Build embeddings and FAISS index
â”œâ”€ chatbot.py            # ğŸ’¬ Main RAG chatbot for CLI
â”œâ”€ test_rag.py           # ğŸ§ª Test and debug RAG pipeline
â”œâ”€ chunks.pkl            # ğŸ’¾ Pickled text chunks
â”œâ”€ greek_index.faiss     # ğŸ’¾ FAISS vector index
â”œâ”€ .env                  # ğŸ”‘ Gemini API key
â””â”€ README.txt            # ğŸ“– This documentation
```

---

## ğŸ”§ Functions Overview

### build_rag_index.py

- `read_pdf(file_path)` â€“ Extract text from a PDF file.
- `chunk_text(text, size=500)` â€“ Split text into smaller chunks.
- Workflow: Load PDFs â†’ Chunk text â†’ Generate embeddings â†’ Build FAISS index â†’ Save index and chunks.

### chatbot.py

- `ask_greek_bot(query, k=5)` â€“ Embed query, retrieve top-k chunks, generate answer using Gemini LLM.
- CLI loop to input questions and print answers.

### test_rag.py

- Test the RAG pipeline: shows top-k retrieved chunks with distances and generates the LLM answer.

---

## âœ… Requirements

- Python 3.12+  
- Packages:
- faiss-cpu
- numpy
- PyPDF2
- python-dotenv
- google-genai

## âš¡ Setup Instructions

### 1ï¸âƒ£ Clone project  
```
git clone <your-repo-url>
cd greekmodel
```
### 2ï¸âƒ£ Create virtual environment
```
python -m venv venv
# Windows
venv\Scripts\activate
# Mac/Linux
source venv/bin/activate
```
### 3ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
```
### 4ï¸âƒ£ Add Gemini API key
Create a .env file in the project root:
```
GEMINI_API_KEY=your_google_gemini_api_key_here
```
### 5ï¸âƒ£ Add PDFs
Place Greek history/mythology PDFs inside the data/ folder.

### 6ï¸âƒ£ Build FAISS index
```
python build_rag_index.py
```
### 7ï¸âƒ£ Run chatbot
```
python chatbot.py
```
### 8ï¸âƒ£ Test RAG pipeline
```
python test_rag.py
```
### ğŸ’¬ Example Questions
```

â€œWho was the king of the Greek gods?â€

â€œWhat happened during the Trojan War?â€

â€œDescribe the Spartan army.â€
```

### âš ï¸ Notes
```
- The AI answers only using context retrieved from your PDFs.
- Add more PDFs and rebuild the index to expand knowledge.
```
